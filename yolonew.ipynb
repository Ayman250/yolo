{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "train_dir = Path('split_train')\n",
    "val_dir = Path('split_val')\n",
    "class DetectionTrainer:\n",
    "    def __init__(self, data_yaml_path):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        self.model = YOLO('yolov8s.pt')\n",
    "        self.data_yaml_path = str(Path(data_yaml_path).absolute())\n",
    "        \n",
    "        # Simplified transforms to reduce memory usage\n",
    "        self.transforms_with_boxes = {\n",
    "            'brightness': A.Compose([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.0, p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'contrast': A.Compose([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.0, contrast_limit=0.3, p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'gamma': A.Compose([\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'noise': A.Compose([\n",
    "                A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'blur': A.Compose([\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'rotation': A.Compose([\n",
    "                A.RandomRotate90(p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'flip': A.Compose([\n",
    "                A.Flip(p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "        }\n",
    "        \n",
    "        self.transforms_no_boxes = {\n",
    "            name: A.Compose([t for t in transform if not isinstance(t, A.Resize)] + [A.Resize(640, 640)])\n",
    "            for name, transform in self.transforms_with_boxes.items()\n",
    "        }\n",
    "\n",
    "    def process_single_image(self, img_path, label_path, dest_dir):\n",
    "        \"\"\"Process a single image with memory management\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(str(img_path))\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not read image {img_path}\")\n",
    "                return\n",
    "            \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            boxes = []\n",
    "            class_labels = []\n",
    "            \n",
    "            if label_path.exists():\n",
    "                with open(label_path) as f:\n",
    "                    for line in f.readlines():\n",
    "                        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                        boxes.append([x_center, y_center, width, height])\n",
    "                        class_labels.append(class_id)\n",
    "\n",
    "            # Save original image\n",
    "            cv2.imwrite(str(dest_dir / 'images' / img_path.name), \n",
    "                       cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            if label_path.exists():\n",
    "                shutil.copy2(label_path, dest_dir / 'labels' / label_path.name)\n",
    "\n",
    "            transforms = self.transforms_with_boxes if boxes else self.transforms_no_boxes\n",
    "            \n",
    "            for transform_name, transform in transforms.items():\n",
    "                aug_img_name = f\"{img_path.stem}_{transform_name}{img_path.suffix}\"\n",
    "                aug_label_name = f\"{img_path.stem}_{transform_name}.txt\"\n",
    "                \n",
    "                if boxes:\n",
    "                    transformed = transform(\n",
    "                        image=image,\n",
    "                        bboxes=boxes,\n",
    "                        class_labels=class_labels\n",
    "                    )\n",
    "                    \n",
    "                    cv2.imwrite(\n",
    "                        str(dest_dir / 'images' / aug_img_name),\n",
    "                        cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "                    )\n",
    "                    \n",
    "                    with open(dest_dir / 'labels' / aug_label_name, 'w') as f:\n",
    "                        for box, label in zip(transformed['bboxes'], transformed['class_labels']):\n",
    "                            f.write(f\"{int(label)} {' '.join(map(str, box))}\\n\")\n",
    "                else:\n",
    "                    transformed = transform(image=image)\n",
    "                    cv2.imwrite(\n",
    "                        str(dest_dir / 'images' / aug_img_name),\n",
    "                        cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "                    )\n",
    "                    \n",
    "                    if label_path.exists():\n",
    "                        shutil.copy2(label_path, dest_dir / 'labels' / aug_label_name)\n",
    "                \n",
    "                # Clear transformed data\n",
    "                transformed = None\n",
    "                \n",
    "            # Clear memory\n",
    "            image = None\n",
    "            boxes = None\n",
    "            class_labels = None\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "\n",
    "    def prepare_split_datasets(self, source_dir, train_dir, val_dir, val_split=0.2):\n",
    "        \"\"\"Split dataset with memory management\"\"\"\n",
    "        source_dir = Path(source_dir)\n",
    "        train_dir = Path(train_dir)\n",
    "        val_dir = Path(val_dir)\n",
    "        \n",
    "        for dir_path in [train_dir / 'images', train_dir / 'labels',\n",
    "                        val_dir / 'images', val_dir / 'labels']:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process images in smaller batches\n",
    "        batch_size = 80\n",
    "        image_files = list((source_dir / 'images').glob('*.jpg'))\n",
    "        \n",
    "        train_imgs, val_imgs = train_test_split(\n",
    "            image_files,\n",
    "            test_size=val_split,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"Processing {len(train_imgs)} training images in batches...\")\n",
    "        for i in range(0, len(train_imgs), batch_size):\n",
    "            batch = train_imgs[i:i + batch_size]\n",
    "            for img_path in batch:\n",
    "                label_path = source_dir / 'labels' / img_path.with_suffix('.txt').name\n",
    "                self.process_single_image(img_path, label_path, train_dir)\n",
    "            gc.collect()\n",
    "            print(f\"Processed batch {i//batch_size + 1}/{len(train_imgs)//batch_size + 1}\")\n",
    "            \n",
    "        print(f\"Processing {len(val_imgs)} validation images...\")\n",
    "        for img_path in val_imgs:\n",
    "            label_path = source_dir / 'labels' / img_path.with_suffix('.txt').name\n",
    "            shutil.copy2(img_path, val_dir / 'images' / img_path.name)\n",
    "            if label_path.exists():\n",
    "                shutil.copy2(label_path, val_dir / 'labels' / label_path.name)\n",
    "        \n",
    "        # Clear memory\n",
    "        train_imgs = None\n",
    "        val_imgs = None\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self, epochs, imgsz=640, batch_size=32):\n",
    "        \"\"\"Train with memory optimization\"\"\"\n",
    "        print(f\"Training on {self.device}\")\n",
    "        \n",
    "        with open(self.data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        \n",
    "        data_config['train'] = str(train_dir / 'images')\n",
    "        data_config['val'] = str(val_dir / 'images')\n",
    "        \n",
    "        temp_yaml_path = 'temp_data.yaml'\n",
    "        with open(temp_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f)\n",
    "        \n",
    "        args = dict(\n",
    "            data=temp_yaml_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,  # Reduced batch size\n",
    "            patience=20,\n",
    "            save_period=10,\n",
    "            verbose=True,\n",
    "            device=self.device,\n",
    "            project=str(Path().absolute() / 'runs'),\n",
    "            augment=True,\n",
    "            cache=False,\n",
    "            workers=4,  # Reduced number of workers\n",
    "            lr0=0.01,\n",
    "            lrf=0.001,\n",
    "            name=\"test_run\"\n",
    "        )\n",
    "        \n",
    "        # try:\n",
    "        self.model.train(**args)\n",
    "        # finally:\n",
    "        #     for dir_path in [train_dir, val_dir]:\n",
    "        #         if dir_path.exists():\n",
    "        #             shutil.rmtree(dir_path)\n",
    "        #     if os.path.exists(temp_yaml_path):\n",
    "        #         os.remove(temp_yaml_path)\n",
    "\n",
    "    def test(self, conf_threshold=0.25, iou_threshold=0.45):\n",
    "        \"\"\"Test the model on the test dataset\"\"\"\n",
    "        print(f\"\\nRunning tests on {self.device}\")\n",
    "        \n",
    "        # Create a temporary yaml file for testing\n",
    "        with open(self.data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        \n",
    "        # Update paths to point to test directory\n",
    "        data_config['val'] = str(Path('test/images'))  # Use test directory for validation\n",
    "        \n",
    "        temp_yaml_path = 'temp_test_data.yaml'\n",
    "        with open(temp_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f)\n",
    "            \n",
    "        results = self.model.val(\n",
    "            data=temp_yaml_path,\n",
    "            split='test',\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            device=0 if self.device.type == 'cuda' else 'cpu',\n",
    "            verbose=True\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Run inference on a single image\"\"\"\n",
    "        return self.model.predict(\n",
    "            source=image_path,\n",
    "            conf=0.25,\n",
    "            iou=0.45,\n",
    "            device=0 if self.device.type == 'cuda' else 'cpu'\n",
    "        )\n",
    "\n",
    "def prepare_dataset_structure():\n",
    "    \"\"\"\n",
    "    Create the simplified dataset structure\n",
    "    \"\"\"\n",
    "    dirs = ['train/images', 'train/labels', \n",
    "            'test/images', 'test/labels']\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def create_data_yaml(dataset_path):\n",
    "    \"\"\"\n",
    "    Create the data.yaml file for YOLOv8\n",
    "    \"\"\"\n",
    "    # Convert to absolute path\n",
    "    abs_path = str(Path(dataset_path).absolute())\n",
    "    \n",
    "    yaml_content = f\"\"\"\n",
    "path: {abs_path}  # dataset root directory\n",
    "train: {abs_path}/train/images  # train images\n",
    "val: {abs_path}/temp_val/images  # temporary validation images directory\n",
    "test: {abs_path}/test/images    # test images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: negative\n",
    "  1: positive\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('data.yaml', 'w') as f:\n",
    "        f.write(yaml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124456/3776920367.py:55: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.\n",
      "  A.Flip(p=1.0),\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get absolute path of current directory\n",
    "current_dir = str(Path().absolute())\n",
    "\n",
    "# Create dataset structure\n",
    "prepare_dataset_structure()\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DetectionTrainer('data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_augments=False\n",
    "if changed_augments:\n",
    "    for dir_path in [train_dir, val_dir]:\n",
    "        if dir_path.exists():\n",
    "            shutil.rmtree(dir_path)\n",
    "    print(\"Preparing train/val splits and augmentations...\")\n",
    "    trainer.prepare_split_datasets('train', train_dir, val_dir, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "New https://pypi.org/project/ultralytics/8.3.41 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=temp_data.yaml, epochs=40, time=None, patience=20, batch=32, imgsz=640, save=True, save_period=10, cache=False, device=cuda, workers=4, project=/home/ayman/ml/pt/yolo/runs, name=test_run7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ayman/ml/pt/yolo/runs/test_run7\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/ayman/ml/pt/yolo/runs/test_run7', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ayman/ml/pt/yolo/split_train/labels.cache... 3400 images, 56 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3456/3456 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ayman/ml/pt/yolo/split_val/labels.cache... 104 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/ayman/ml/pt/yolo/runs/test_run7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/ayman/ml/pt/yolo/runs/test_run7\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      7.35G      1.263      2.363      1.194         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:31<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.238      0.515      0.233      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      7.31G      1.128      1.303      1.106         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:30<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.447      0.725       0.48      0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      7.31G      1.091      1.237      1.087         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:27<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.434      0.813      0.416      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      7.31G      1.107      1.226      1.098         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:27<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.459      0.786      0.516      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      7.31G      1.067      1.157      1.071         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:28<00:00,  3.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.411      0.773      0.513      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      7.31G      1.038      1.105      1.059         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:26<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.414      0.689      0.543      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      7.31G     0.9869      1.032      1.035         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:28<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.535      0.713      0.611      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      7.31G     0.9659     0.9837      1.024         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:28<00:00,  3.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.466      0.813      0.632      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      7.31G     0.9406      0.935      1.018         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.548       0.72      0.659      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      7.31G      0.914     0.8736      1.008         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.486      0.742      0.598      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      7.31G     0.8996     0.8291     0.9962         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.628      0.674      0.684      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      7.31G     0.8748     0.7898     0.9858         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:26<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.643      0.709      0.698      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      7.31G     0.8624      0.778     0.9874         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:26<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.663      0.657      0.676      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      7.31G     0.8323     0.7279     0.9773         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.576      0.853       0.74      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      7.31G     0.8415     0.7136     0.9762         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.546      0.748      0.708      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      7.31G     0.8191     0.6813     0.9702         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:24<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.529      0.763      0.578      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      7.31G     0.7785     0.6306     0.9489         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:26<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.649      0.721      0.738      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      7.31G      0.766     0.6261     0.9481         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.598      0.755      0.712      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      7.31G     0.7578      0.596     0.9467         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:24<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.643      0.694      0.717       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      7.31G      0.743     0.5749     0.9402         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.796      0.724      0.795      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      7.31G     0.7168     0.5556      0.929         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.717      0.756      0.784      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      7.31G     0.7263     0.5557      0.936         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.686      0.779      0.804      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40      7.31G     0.7017     0.5154     0.9257         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.753      0.741      0.783      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40      7.31G     0.6959     0.5116     0.9273         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.713      0.779      0.801       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      7.31G     0.6639     0.4917     0.9144         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.741      0.609      0.746      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40      7.31G     0.6494     0.4719      0.911         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:24<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.693        0.8      0.825      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40      7.31G     0.6438     0.4558     0.9119         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.605      0.834      0.789      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40      7.31G     0.6428     0.4635     0.9072         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:25<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        108        111      0.657      0.777      0.799      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40      7.31G     0.6157     0.4292     0.8952         43        640:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 53/108 [00:13<00:13,  3.97it/s]"
     ]
    }
   ],
   "source": [
    "# Create data.yaml with absolute paths\n",
    "create_data_yaml(current_dir)\n",
    "\n",
    "# Train model\n",
    "trainer.train(epochs=40)\n",
    "\n",
    "\n",
    "# Run tests and get results\n",
    "test_results = trainer.test(conf_threshold=0.25, iou_threshold=0.45)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
