{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "train_dir = Path('split_train')\n",
    "val_dir = Path('split_val')\n",
    "dev='cuda'\n",
    "class DetectionTrainer:\n",
    "    def __init__(self, data_yaml_path):\n",
    "        self.device = dev\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        self.model = YOLO('yolov8s.pt')\n",
    "        self.data_yaml_path = str(Path(data_yaml_path).absolute())\n",
    "        \n",
    "        # Simplified transforms to reduce memory usage\n",
    "        self.transforms_with_boxes = {\n",
    "            'brightness': A.Compose([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.0, p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'contrast': A.Compose([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.0, contrast_limit=0.3, p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'gamma': A.Compose([\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'noise': A.Compose([\n",
    "                A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'blur': A.Compose([\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'rotation': A.Compose([\n",
    "                A.RandomRotate90(p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "            \n",
    "            'flip': A.Compose([\n",
    "                A.Flip(p=1.0),\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])),\n",
    "        }\n",
    "        \n",
    "        self.transforms_no_boxes = {\n",
    "            name: A.Compose([t for t in transform if not isinstance(t, A.Resize)] + [A.Resize(640, 640)])\n",
    "            for name, transform in self.transforms_with_boxes.items()\n",
    "        }\n",
    "\n",
    "    def process_single_image(self, img_path, label_path, dest_dir):\n",
    "        \"\"\"Process a single image with memory management\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(str(img_path))\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not read image {img_path}\")\n",
    "                return\n",
    "            \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            boxes = []\n",
    "            class_labels = []\n",
    "            \n",
    "            if label_path.exists():\n",
    "                with open(label_path) as f:\n",
    "                    for line in f.readlines():\n",
    "                        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                        boxes.append([x_center, y_center, width, height])\n",
    "                        class_labels.append(class_id)\n",
    "\n",
    "            # Save original image\n",
    "            cv2.imwrite(str(dest_dir / 'images' / img_path.name), \n",
    "                       cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            if label_path.exists():\n",
    "                shutil.copy2(label_path, dest_dir / 'labels' / label_path.name)\n",
    "\n",
    "            transforms = self.transforms_with_boxes if boxes else self.transforms_no_boxes\n",
    "            \n",
    "            for transform_name, transform in transforms.items():\n",
    "                aug_img_name = f\"{img_path.stem}_{transform_name}{img_path.suffix}\"\n",
    "                aug_label_name = f\"{img_path.stem}_{transform_name}.txt\"\n",
    "                \n",
    "                if boxes:\n",
    "                    transformed = transform(\n",
    "                        image=image,\n",
    "                        bboxes=boxes,\n",
    "                        class_labels=class_labels\n",
    "                    )\n",
    "                    \n",
    "                    cv2.imwrite(\n",
    "                        str(dest_dir / 'images' / aug_img_name),\n",
    "                        cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "                    )\n",
    "                    \n",
    "                    with open(dest_dir / 'labels' / aug_label_name, 'w') as f:\n",
    "                        for box, label in zip(transformed['bboxes'], transformed['class_labels']):\n",
    "                            f.write(f\"{int(label)} {' '.join(map(str, box))}\\n\")\n",
    "                else:\n",
    "                    transformed = transform(image=image)\n",
    "                    cv2.imwrite(\n",
    "                        str(dest_dir / 'images' / aug_img_name),\n",
    "                        cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "                    )\n",
    "                    \n",
    "                    if label_path.exists():\n",
    "                        shutil.copy2(label_path, dest_dir / 'labels' / aug_label_name)\n",
    "                \n",
    "                # Clear transformed data\n",
    "                transformed = None\n",
    "                \n",
    "            # Clear memory\n",
    "            image = None\n",
    "            boxes = None\n",
    "            class_labels = None\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "\n",
    "    def prepare_split_datasets(self, source_dir, train_dir, val_dir, val_split=0.2):\n",
    "        \"\"\"Split dataset with memory management\"\"\"\n",
    "        source_dir = Path(source_dir)\n",
    "        train_dir = Path(train_dir)\n",
    "        val_dir = Path(val_dir)\n",
    "        \n",
    "        for dir_path in [train_dir / 'images', train_dir / 'labels',\n",
    "                        val_dir / 'images', val_dir / 'labels']:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process images in smaller batches\n",
    "        batch_size = 80\n",
    "        image_files = list((source_dir / 'images').glob('*.jpg'))\n",
    "        \n",
    "        train_imgs, val_imgs = train_test_split(\n",
    "            image_files,\n",
    "            test_size=val_split,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"Processing {len(train_imgs)} training images in batches...\")\n",
    "        for i in range(0, len(train_imgs), batch_size):\n",
    "            batch = train_imgs[i:i + batch_size]\n",
    "            for img_path in batch:\n",
    "                label_path = source_dir / 'labels' / img_path.with_suffix('.txt').name\n",
    "                self.process_single_image(img_path, label_path, train_dir)\n",
    "            gc.collect()\n",
    "            print(f\"Processed batch {i//batch_size + 1}/{len(train_imgs)//batch_size + 1}\")\n",
    "            \n",
    "        print(f\"Processing {len(val_imgs)} validation images...\")\n",
    "        for img_path in val_imgs:\n",
    "            label_path = source_dir / 'labels' / img_path.with_suffix('.txt').name\n",
    "            shutil.copy2(img_path, val_dir / 'images' / img_path.name)\n",
    "            if label_path.exists():\n",
    "                shutil.copy2(label_path, val_dir / 'labels' / label_path.name)\n",
    "        \n",
    "        # Clear memory\n",
    "        train_imgs = None\n",
    "        val_imgs = None\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self, epochs, imgsz=640, batch_size=32):\n",
    "        \"\"\"Train with memory optimization\"\"\"\n",
    "        print(f\"Training on {self.device}\")\n",
    "        \n",
    "        with open(self.data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        \n",
    "        data_config['train'] = str(train_dir / 'images')\n",
    "        data_config['val'] = str(val_dir / 'images')\n",
    "        \n",
    "        temp_yaml_path = 'temp_data.yaml'\n",
    "        with open(temp_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f)\n",
    "        \n",
    "        args = dict(\n",
    "            data=temp_yaml_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,  # Reduced batch size\n",
    "            patience=20,\n",
    "            save_period=10,\n",
    "            verbose=True,\n",
    "            device=self.device,\n",
    "            project=str(Path().absolute() / 'runs'),\n",
    "            augment=True,\n",
    "            cache=False,\n",
    "            workers=4,  # Reduced number of workers\n",
    "            lr0=0.01,\n",
    "            lrf=0.001,\n",
    "            name=\"test_run\"\n",
    "        )\n",
    "        \n",
    "        # try:\n",
    "        self.model.train(**args)\n",
    "        # finally:\n",
    "        #     for dir_path in [train_dir, val_dir]:\n",
    "        #         if dir_path.exists():\n",
    "        #             shutil.rmtree(dir_path)\n",
    "        #     if os.path.exists(temp_yaml_path):\n",
    "        #         os.remove(temp_yaml_path)\n",
    "\n",
    "    def test(self, conf_threshold=0.25, iou_threshold=0.45):\n",
    "        \"\"\"Test the model on the test dataset\"\"\"\n",
    "        print(f\"\\nRunning tests on {self.device}\")\n",
    "        \n",
    "        # Create a temporary yaml file for testing\n",
    "        with open(self.data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        \n",
    "        # Update paths to point to test directory\n",
    "        data_config['val'] = str(Path('test/images'))  # Use test directory for validation\n",
    "        \n",
    "        temp_yaml_path = 'temp_test_data.yaml'\n",
    "        with open(temp_yaml_path, 'w') as f:\n",
    "            yaml.dump(data_config, f)\n",
    "            \n",
    "        results = self.model.val(\n",
    "            data=temp_yaml_path,\n",
    "            split='test',\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            device=dev,\n",
    "            verbose=True\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Run inference on a single image\"\"\"\n",
    "        return self.model.predict(\n",
    "            source=image_path,\n",
    "            conf=0.25,\n",
    "            iou=0.45,\n",
    "            device=dev\n",
    "        )\n",
    "\n",
    "def prepare_dataset_structure():\n",
    "    \"\"\"\n",
    "    Create the simplified dataset structure\n",
    "    \"\"\"\n",
    "    dirs = ['train/images', 'train/labels', \n",
    "            'test/images', 'test/labels']\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def create_data_yaml(dataset_path):\n",
    "    \"\"\"\n",
    "    Create the data.yaml file for YOLOv8\n",
    "    \"\"\"\n",
    "    # Convert to absolute path\n",
    "    abs_path = str(Path(dataset_path).absolute())\n",
    "    \n",
    "    yaml_content = f\"\"\"\n",
    "path: {abs_path}  # dataset root directory\n",
    "train: {abs_path}/train/images  # train images\n",
    "val: {abs_path}/temp_val/images  # temporary validation images directory\n",
    "test: {abs_path}/test/images    # test images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: negative\n",
    "  1: positive\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('data.yaml', 'w') as f:\n",
    "        f.write(yaml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get absolute path of current directory\n",
    "current_dir = str(Path().absolute())\n",
    "\n",
    "# Create dataset structure\n",
    "prepare_dataset_structure()\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DetectionTrainer('data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_augments=False\n",
    "if changed_augments:\n",
    "    for dir_path in [train_dir, val_dir]:\n",
    "        if dir_path.exists():\n",
    "            shutil.rmtree(dir_path)\n",
    "    print(\"Preparing train/val splits and augmentations...\")\n",
    "    trainer.prepare_split_datasets('train', train_dir, val_dir, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml with absolute paths\n",
    "create_data_yaml(current_dir)\n",
    "\n",
    "# Train model\n",
    "trainer.train(epochs=40)\n",
    "\n",
    "\n",
    "# Run tests and get results\n",
    "test_results = trainer.test(conf_threshold=0.25, iou_threshold=0.45)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
