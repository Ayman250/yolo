{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayman/.local/lib/python3.10/site-packages/pydantic/main.py:209: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "/tmp/ipykernel_170897/575657221.py:35: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.\n",
      "  A.Flip(p=0.5),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 161\u001b[0m\n\u001b[1;32m    158\u001b[0m     results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/images/example.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 155\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CartDetectionTrainer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Train model with automatic validation split\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 20% validation split\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Example inference\u001b[39;00m\n\u001b[1;32m    158\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/images/example.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m, in \u001b[0;36mCartDetectionTrainer.train\u001b[0;34m(self, epochs, imgsz, batch_size, val_split)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Split into train and validation\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_images))\n\u001b[0;32m---> 53\u001b[0m train_imgs, val_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Create temporary validation directory structure\u001b[39;00m\n\u001b[1;32m     60\u001b[0m val_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_val\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2312\u001b[0m     )\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DetectionTrainer:\n",
    "    def __init__(self, data_yaml_path):\n",
    "        \"\"\"\n",
    "        Initialize the trainer with path to data.yaml file\n",
    "        data_yaml_path: Path to YAML file containing dataset configuration\n",
    "        \"\"\"\n",
    "        self.model = YOLO('yolov8n.pt')  # Start with a pre-trained YOLOv8 nano model\n",
    "        self.data_yaml_path = str(Path(data_yaml_path).absolute())\n",
    "        \n",
    "        # Define augmentation pipeline\n",
    "        self.train_transforms = A.Compose([\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.RandomGamma(p=0.5),\n",
    "            A.GaussNoise(p=0.3),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(p=0.5),\n",
    "                A.MedianBlur(blur_limit=3, p=0.5),\n",
    "                A.GaussianBlur(blur_limit=3, p=0.5),\n",
    "            ], p=0.3),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(p=0.3),\n",
    "                A.GridDistortion(p=0.3),\n",
    "            ], p=0.2),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Flip(p=0.5),\n",
    "            A.Resize(640, 640),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "    def train(self, epochs=100, imgsz=640, batch_size=16, val_split=0.2):\n",
    "        \"\"\"\n",
    "        Train the model with automatic validation split\n",
    "        \"\"\"\n",
    "        # Get list of all training images\n",
    "        train_images = list(Path('train/images').glob('*.jpg'))\n",
    "        \n",
    "        # Split into train and validation\n",
    "        train_imgs, val_imgs = train_test_split(\n",
    "            train_images, \n",
    "            test_size=val_split,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Create temporary validation directory structure\n",
    "        val_dir = Path('temp_val')\n",
    "        val_img_dir = val_dir / 'images'\n",
    "        val_label_dir = val_dir / 'labels'\n",
    "        \n",
    "        # Create temporary training directory structure\n",
    "        temp_train_dir = Path('temp_train')\n",
    "        temp_train_img_dir = temp_train_dir / 'images'\n",
    "        temp_train_label_dir = temp_train_dir / 'labels'\n",
    "        \n",
    "        # Create all directories\n",
    "        for dir_path in [val_img_dir, val_label_dir, temp_train_img_dir, temp_train_label_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Move files to appropriate directories\n",
    "        for img_path in train_imgs:\n",
    "            # Copy training images\n",
    "            new_img_path = temp_train_img_dir / img_path.name\n",
    "            shutil.copy2(img_path, new_img_path)\n",
    "            \n",
    "            # Copy training labels\n",
    "            label_path = Path('train/labels') / img_path.with_suffix('.txt').name\n",
    "            if label_path.exists():\n",
    "                new_label_path = temp_train_label_dir / label_path.name\n",
    "                shutil.copy2(label_path, new_label_path)\n",
    "        \n",
    "        for img_path in val_imgs:\n",
    "            # Copy validation images\n",
    "            new_img_path = val_img_dir / img_path.name\n",
    "            shutil.copy2(img_path, new_img_path)\n",
    "            \n",
    "            # Copy validation labels\n",
    "            label_path = Path('train/labels') / img_path.with_suffix('.txt').name\n",
    "            if label_path.exists():\n",
    "                new_label_path = val_label_dir / label_path.name\n",
    "                shutil.copy2(label_path, new_label_path)\n",
    "        \n",
    "        # Get absolute paths for training\n",
    "        project_dir = Path().absolute()\n",
    "        \n",
    "        # Update data.yaml with temporary directories\n",
    "        temp_yaml_path = 'temp_data.yaml'\n",
    "        with open(self.data_yaml_path, 'r') as f:\n",
    "            yaml_content = f.read()\n",
    "        yaml_content = yaml_content.replace('train/images', 'temp_train/images')\n",
    "        with open(temp_yaml_path, 'w') as f:\n",
    "            f.write(yaml_content)\n",
    "        \n",
    "        # Training arguments\n",
    "        args = dict(\n",
    "            data=temp_yaml_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,\n",
    "            patience=20,  # Early stopping patience\n",
    "            save_period=10,  # Save checkpoint every 10 epochs\n",
    "            verbose=True,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            project=str(project_dir / 'runs'),  # Save results to runs/\n",
    "            augment=True  # Use built-in YOLOv8 augmentations\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            self.model.train(**args)\n",
    "        finally:\n",
    "            # Clean up temporary directories\n",
    "            for temp_dir in [val_dir, temp_train_dir]:\n",
    "                if temp_dir.exists():\n",
    "                    shutil.rmtree(temp_dir)\n",
    "            # Remove temporary yaml file\n",
    "            if os.path.exists(temp_yaml_path):\n",
    "                os.remove(temp_yaml_path)\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Run inference on a single image\n",
    "        \"\"\"\n",
    "        results = self.model.predict(\n",
    "            source=image_path,\n",
    "            conf=0.25,  # Confidence threshold\n",
    "            iou=0.45    # NMS IoU threshold\n",
    "        )\n",
    "        return results\n",
    "\n",
    "def prepare_dataset_structure():\n",
    "    \"\"\"\n",
    "    Create the simplified dataset structure\n",
    "    \"\"\"\n",
    "    dirs = ['train/images', 'train/labels', \n",
    "            'test/images', 'test/labels']\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def create_data_yaml(dataset_path):\n",
    "    \"\"\"\n",
    "    Create the data.yaml file for YOLOv8\n",
    "    \"\"\"\n",
    "    # Convert to absolute path\n",
    "    abs_path = str(Path(dataset_path).absolute())\n",
    "    \n",
    "    yaml_content = f\"\"\"\n",
    "path: {abs_path}  # dataset root directory\n",
    "train: {abs_path}/train/images  # train images\n",
    "val: {abs_path}/temp_val/images  # temporary validation images directory\n",
    "test: {abs_path}/test/images    # test images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: shopping cart\n",
    "  1: filled BOB\n",
    "  2: empty BOB\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('data.yaml', 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "def main():\n",
    "    # Get absolute path of current directory\n",
    "    current_dir = str(Path().absolute())\n",
    "    \n",
    "    # Create dataset structure\n",
    "    prepare_dataset_structure()\n",
    "    \n",
    "    # Create data.yaml with absolute paths\n",
    "    create_data_yaml(current_dir)\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = DetectionTrainer('data.yaml')\n",
    "    \n",
    "    # Train model with automatic validation split\n",
    "    trainer.train(val_split=0.2)  # 20% validation split\n",
    "    \n",
    "    # Example inference\n",
    "    results = trainer.predict('test/images/example.jpg')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
